{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from nnterp import load_model\n",
    "import torch as th\n",
    "\n",
    "th.set_grad_enabled(False)\n",
    "import gc\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from utils import feature_df\n",
    "import json\n",
    "from dictionary_learning import CrossCoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from contextlib import nullcontext\n",
    "from tools.paths import DATA_ROOT\n",
    "\n",
    "twins = th.tensor(json.load(open(\"../data/twins.json\")))\n",
    "gemma_2 = load_model(\"google/gemma-2-2b\", device_map=\"cuda:0\")\n",
    "gemma_2_it = load_model(\n",
    "    \"google/gemma-2-2b-it\", device_map=f\"cuda:{th.cuda.device_count() - 1}\"\n",
    ")\n",
    "# df = feature_df()\n",
    "# crosscoder = Crosscoder.from_pretrained\n",
    "crosscoder = CrossCoder.from_pretrained(\n",
    "    \"Butanium/gemma-2-2b-crosscoder-l13-mu4.1e-02-lr1e-04\", from_hub=True, device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = th.load(\n",
    "    DATA_ROOT / \"/results/it_base_twins_activation_statistics_N10000000.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.keys() dict_keys(['count_joint', 'count_A', 'count_B', 'count_A_B', 'count_B_A', 'count_total', 'correAB', 'correBA'])\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(5, 2, figsize=(15, 25))\n",
    "fig.suptitle(\"Activation Statistics Histograms\")\n",
    "\n",
    "# Flatten axs for easier iteration\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Plot histograms for each tensor in results\n",
    "for i, (key, tensor) in enumerate(results.items()):\n",
    "    if key == \"count_total\":\n",
    "        continue\n",
    "    print(key, tensor.shape, tensor.min(), tensor.max())\n",
    "    axs[i].hist(tensor.cpu().numpy().flatten())\n",
    "    axs[i].set_title(key.replace(\"A\", \"chat\").replace(\"B\", \"base\"))\n",
    "    axs[i].set_xlabel(\"Value\")\n",
    "    axs[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Calculate and plot P(A|B) and P(B|A)\n",
    "P_A_given_B = results[\"count_joint\"] / results[\"count_B\"]\n",
    "P_B_given_A = results[\"count_joint\"] / results[\"count_A\"]\n",
    "\n",
    "axs[8].hist(P_A_given_B.cpu().numpy().flatten())\n",
    "axs[8].set_title(\"P(chat|base)\")\n",
    "axs[8].set_xlabel(\"Value\")\n",
    "axs[8].set_ylabel(\"Frequency\")\n",
    "\n",
    "axs[9].hist(P_B_given_A.cpu().numpy().flatten())\n",
    "axs[9].set_title(\"P(base|chat)\")\n",
    "axs[9].set_xlabel(\"Value\")\n",
    "axs[9].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show twins with min P(A|B) and print their P(B|A) and vice versa\n",
    "# Find indices of min P(A|B) and P(B|A)\n",
    "min_P_A_given_B_idx = th.argmin(P_A_given_B)\n",
    "min_P_B_given_A_idx = th.argmin(P_B_given_A)\n",
    "\n",
    "print(\"Twin pair with minimum P(A|B):\")\n",
    "print(f\"P(A|B) = {P_A_given_B.flatten()[min_P_A_given_B_idx]:.4f}\")\n",
    "print(f\"P(B|A) = {P_B_given_A.flatten()[min_P_A_given_B_idx]:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Twin pair with minimum P(B|A):\")\n",
    "print(f\"P(A|B) = {P_A_given_B.flatten()[min_P_B_given_A_idx]:.4f}\")\n",
    "print(f\"P(B|A) = {P_B_given_A.flatten()[min_P_B_given_A_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_A_given_B = results[\"count_joint\"] / results[\"count_B\"]\n",
    "P_B_given_A = results[\"count_joint\"] / results[\"count_A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch as th\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from torch.nn.functional import kl_div\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Any, Union\n",
    "\n",
    "from torch import Tensor\n",
    "from torchmetrics.aggregation import BaseAggregator\n",
    "\n",
    "\n",
    "template_path = \"../templates/gemma_chat_template_ctrl_tokens.jinja\"\n",
    "chat_template_path = \"../templates/gemma_chat_template.jinja\"\n",
    "with open(template_path, \"r\") as f:\n",
    "    ctrl_template = f.read()\n",
    "with open(chat_template_path, \"r\") as f:\n",
    "    chat_template = f.read()\n",
    "\n",
    "\n",
    "def feature_df():\n",
    "    global df\n",
    "    if df is None:\n",
    "        df_path = hf_hub_download(\n",
    "            repo_id=\"Butanium/max-activating-examples-gemma-2-2b-l13-mu4.1e-02-lr1e-04\",\n",
    "            filename=\"feature_df.csv\",\n",
    "            repo_type=\"dataset\",\n",
    "        )\n",
    "        df = pd.read_csv(df_path, index_col=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def base_only_latent_indices():\n",
    "    df = feature_df()\n",
    "    # filter for tag = Base only\n",
    "    return th.tensor(df[df[\"tag\"] == \"Base only\"].index.tolist())\n",
    "\n",
    "\n",
    "def it_only_latent_indices():\n",
    "    df = feature_df()\n",
    "    # filter for tag = IT only\n",
    "    return th.tensor(df[df[\"tag\"] == \"IT only\"].index.tolist())\n",
    "\n",
    "\n",
    "def shared_latent_indices():\n",
    "    df = feature_df()\n",
    "    # filter for tag = Shared\n",
    "    return th.tensor(df[df[\"tag\"] == \"Shared\"].index.tolist())\n",
    "\n",
    "\n",
    "class CCLatent:\n",
    "    def __init__(self, id_: int):\n",
    "        self.id = id_\n",
    "        self.tag = df.loc[id_, \"tag\"]\n",
    "\n",
    "    def stats(self):\n",
    "        return feature_df().loc[self.id]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "=================================\n",
    "=                               =\n",
    "=         Plotting utils        =\n",
    "=                               =\n",
    "=================================\n",
    "\"\"\"\n",
    "from tiny_dashboard.html_utils import (\n",
    "    create_token_html,\n",
    "    create_example_html,\n",
    "    create_base_html,\n",
    ")\n",
    "from tiny_dashboard.utils import sanitize_tokens, sanitize_token\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pylab import apply_alpha\n",
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def activation_visualization(\n",
    "    tokens: list[str],\n",
    "    activations: th.Tensor,\n",
    "    tokenizer,\n",
    "    highlight_idx: int | None = None,\n",
    "    title: str = \"\",\n",
    ") -> str:\n",
    "    \"\"\"Create HTML with highlighted tokens based on activation values\"\"\"\n",
    "    html_parts = []\n",
    "    # all_feature_indicies = list(range(activations.shape[0]))\n",
    "    # Find highlight feature index in the activation tensor\n",
    "    if highlight_idx is None:\n",
    "        if activations.dim() == 2:\n",
    "            raise ValueError(\n",
    "                \"Activations must be 1D unless a highlight feature is specified\"\n",
    "            )\n",
    "        highlight_acts = activations\n",
    "        activations = activations.unsqueeze(0)\n",
    "        other_features = [0]\n",
    "    else:\n",
    "        highlight_acts = activations[highlight_idx]\n",
    "        other_features = [i for i in range(activations.shape[0]) if i != highlight_idx]\n",
    "    # Normalize activations for color intensity (only for highlight feature)\n",
    "    max_highlight = highlight_acts.max()\n",
    "    norm_acts = highlight_acts / (max_highlight + 1e-6)\n",
    "\n",
    "    # Create HTML spans with activation values\n",
    "    sanitized_tokens = sanitize_tokens(tokens, non_breaking_space=False)\n",
    "    for i, (san_token, token) in enumerate(zip(sanitized_tokens, tokens)):\n",
    "\n",
    "        color = f\"rgba(255, 0, 0, {norm_acts[i].item():.3f})\"\n",
    "\n",
    "        # Create tooltip content only for requested features\n",
    "        tok_id = tokenizer.convert_tokens_to_ids(token)\n",
    "        tooltip_token = sanitize_token(\n",
    "            token, keep_newline=False, non_breaking_space=False\n",
    "        )\n",
    "        tooltip_lines = [f\"Token {tok_id}: '{tooltip_token}'\"]\n",
    "        for feat in other_features:\n",
    "            act_value = activations[feat, i].item()\n",
    "            tooltip_lines.append(f\"Feature {feat}: {act_value:.3f}\")\n",
    "\n",
    "        tooltip_content = \"\\n\".join(tooltip_lines)\n",
    "        html_parts.append(create_token_html(san_token, color, tooltip_content))\n",
    "\n",
    "    html = \"\".join(html_parts)\n",
    "    html = create_example_html(max_highlight.item(), html, static=True)\n",
    "    return create_base_html(title, html)\n",
    "\n",
    "\n",
    "def draw_networkx_nodes(\n",
    "    G,\n",
    "    pos,\n",
    "    nodelist=None,\n",
    "    node_size=300,\n",
    "    node_color=\"#1f78b4\",\n",
    "    node_shape=\"o\",\n",
    "    alpha=None,\n",
    "    cmap=None,\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "    ax=None,\n",
    "    linewidths=None,\n",
    "    edgecolors=None,\n",
    "    label=None,\n",
    "    margins=None,\n",
    "    hide_ticks=True,\n",
    "):\n",
    "    \"\"\"Draw the nodes of the graph G.\n",
    "\n",
    "    This draws only the nodes of the graph G.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : graph\n",
    "        A networkx graph\n",
    "\n",
    "    pos : dictionary\n",
    "        A dictionary with nodes as keys and positions as values.\n",
    "        Positions should be sequences of length 2.\n",
    "\n",
    "    ax : Matplotlib Axes object, optional\n",
    "        Draw the graph in the specified Matplotlib axes.\n",
    "\n",
    "    nodelist : list (default list(G))\n",
    "        Draw only specified nodes\n",
    "\n",
    "    node_size : scalar or array (default=300)\n",
    "        Size of nodes.  If an array it must be the same length as nodelist.\n",
    "\n",
    "    node_color : color or array of colors (default='#1f78b4')\n",
    "        Node color. Can be a single color or a sequence of colors with the same\n",
    "        length as nodelist. Color can be string or rgb (or rgba) tuple of\n",
    "        floats from 0-1. If numeric values are specified they will be\n",
    "        mapped to colors using the cmap and vmin,vmax parameters. See\n",
    "        matplotlib.scatter for more details.\n",
    "\n",
    "    node_shape :  string (default='o')\n",
    "        The shape of the node.  Specification is as matplotlib.scatter\n",
    "        marker, one of 'so^>v<dph8'.\n",
    "\n",
    "    alpha : float or array of floats (default=None)\n",
    "        The node transparency.  This can be a single alpha value,\n",
    "        in which case it will be applied to all the nodes of color. Otherwise,\n",
    "        if it is an array, the elements of alpha will be applied to the colors\n",
    "        in order (cycling through alpha multiple times if necessary).\n",
    "\n",
    "    cmap : Matplotlib colormap (default=None)\n",
    "        Colormap for mapping intensities of nodes\n",
    "\n",
    "    vmin,vmax : floats or None (default=None)\n",
    "        Minimum and maximum for node colormap scaling\n",
    "\n",
    "    linewidths : [None | scalar | sequence] (default=1.0)\n",
    "        Line width of symbol border\n",
    "\n",
    "    edgecolors : [None | scalar | sequence] (default = node_color)\n",
    "        Colors of node borders. Can be a single color or a sequence of colors with the\n",
    "        same length as nodelist. Color can be string or rgb (or rgba) tuple of floats\n",
    "        from 0-1. If numeric values are specified they will be mapped to colors\n",
    "        using the cmap and vmin,vmax parameters. See `~matplotlib.pyplot.scatter` for more details.\n",
    "\n",
    "    label : [None | string]\n",
    "        Label for legend\n",
    "\n",
    "    margins : float or 2-tuple, optional\n",
    "        Sets the padding for axis autoscaling. Increase margin to prevent\n",
    "        clipping for nodes that are near the edges of an image. Values should\n",
    "        be in the range ``[0, 1]``. See :meth:`matplotlib.axes.Axes.margins`\n",
    "        for details. The default is `None`, which uses the Matplotlib default.\n",
    "\n",
    "    hide_ticks : bool, optional\n",
    "        Hide ticks of axes. When `True` (the default), ticks and ticklabels\n",
    "        are removed from the axes. To set ticks and tick labels to the pyplot default,\n",
    "        use ``hide_ticks=False``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.collections.PathCollection\n",
    "        `PathCollection` of the nodes.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> G = nx.dodecahedral_graph()\n",
    "    >>> nodes = nx.draw_networkx_nodes(G, pos=nx.spring_layout(G))\n",
    "\n",
    "    Also see the NetworkX drawing examples at\n",
    "    https://networkx.org/documentation/latest/auto_examples/index.html\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    draw\n",
    "    draw_networkx\n",
    "    draw_networkx_edges\n",
    "    draw_networkx_labels\n",
    "    draw_networkx_edge_labels\n",
    "    \"\"\"\n",
    "    from collections.abc import Iterable\n",
    "\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.collections  # call as mpl.collections\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if nodelist is None:\n",
    "        nodelist = list(G)\n",
    "\n",
    "    if len(nodelist) == 0:  # empty nodelist, no drawing\n",
    "        return mpl.collections.PathCollection(None)\n",
    "\n",
    "    try:\n",
    "        xy = np.asarray([pos[v] for v in nodelist])\n",
    "    except KeyError as err:\n",
    "        raise nx.NetworkXError(f\"Node {err} has no position.\") from err\n",
    "\n",
    "    if isinstance(alpha, Iterable):\n",
    "        node_color = apply_alpha(node_color, alpha, nodelist, cmap, vmin, vmax)\n",
    "        alpha = None\n",
    "\n",
    "    # Convert node_shape to array if it's not already\n",
    "    if not isinstance(node_shape, (np.ndarray, list)):\n",
    "        node_shape = [node_shape] * len(nodelist)\n",
    "    node_shape = np.asarray(node_shape)\n",
    "\n",
    "    # Convert node_color to array if it's not already\n",
    "    if not isinstance(node_color, (np.ndarray, list)):\n",
    "        node_color = [node_color] * len(nodelist)\n",
    "    node_color = np.asarray(node_color)\n",
    "\n",
    "    # Create collections for each unique shape-color combination\n",
    "    collections = []\n",
    "\n",
    "    for shape in np.unique(node_shape):\n",
    "        shape_mask = node_shape == shape\n",
    "        shape_xy = xy[shape_mask]\n",
    "        shape_colors = node_color[shape_mask]\n",
    "\n",
    "        node_collection = ax.scatter(\n",
    "            shape_xy[:, 0],\n",
    "            shape_xy[:, 1],\n",
    "            s=node_size,\n",
    "            c=shape_colors,\n",
    "            marker=shape,\n",
    "            cmap=cmap,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            alpha=alpha,\n",
    "            linewidths=linewidths,\n",
    "            edgecolors=edgecolors,\n",
    "            label=label,\n",
    "        )\n",
    "        collections.append(node_collection)\n",
    "\n",
    "    if hide_ticks:\n",
    "        ax.tick_params(\n",
    "            axis=\"both\",\n",
    "            which=\"both\",\n",
    "            bottom=False,\n",
    "            left=False,\n",
    "            labelbottom=False,\n",
    "            labelleft=False,\n",
    "        )\n",
    "\n",
    "    if margins is not None:\n",
    "        if isinstance(margins, Iterable):\n",
    "            ax.margins(*margins)\n",
    "        else:\n",
    "            ax.margins(margins)\n",
    "\n",
    "    # Set zorder for all collections\n",
    "    for collection in collections:\n",
    "        collection.set_zorder(2)\n",
    "\n",
    "    # Return the last collection for compatibility\n",
    "    return collections[-1] if collections else None\n",
    "\n",
    "\n",
    "def plot_component_sizes(G, title=None):\n",
    "    # bar plot of the size of the connected components\n",
    "    component_sizes = [len(c) for c in nx.connected_components(G)]\n",
    "    print(f\"found {len(component_sizes)} connected components\")\n",
    "    # Count frequency of each size\n",
    "    from collections import Counter\n",
    "\n",
    "    size_counts = Counter(component_sizes)\n",
    "    # Convert to lists for plotting and sort\n",
    "    sizes = sorted(list(size_counts.keys()))\n",
    "    counts = [size_counts[size] for size in sizes]\n",
    "    fig = px.bar(\n",
    "        x=sizes,\n",
    "        y=counts,\n",
    "        title=\"Distribution of connected component sizes\" if title is None else title,\n",
    "        labels={\"x\": \"Component size\", \"y\": \"Number of components\"},\n",
    "    )\n",
    "    # Only show x-axis ticks for values that exist in the data\n",
    "    fig.update_xaxes(tickmode=\"array\", tickvals=sizes, type=\"category\")\n",
    "    fig.show()\n",
    "    # bar plot where x is the component size and y is the number of nodes in those components\n",
    "    y = [size_counts[size] * size for size in sizes]\n",
    "    fig = px.bar(\n",
    "        x=sizes,\n",
    "        y=y,\n",
    "        title=(\n",
    "            \"Distribution of latent in different component sizes\" + \"\\n\"\n",
    "            if title is None\n",
    "            else title\n",
    "        ),\n",
    "        labels={\"x\": \"Component size\", \"y\": \"Number of latents\"},\n",
    "    )\n",
    "    # Only show x-axis ticks for values that exist in the data\n",
    "    fig.update_xaxes(tickmode=\"array\", tickvals=sizes, type=\"category\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def draw_graph(G, title=\"\"):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    pos = nx.spring_layout(G, k=0.035)  # reduced k from default\n",
    "\n",
    "    # Create node color list and prepare for legend\n",
    "    node_colors = []\n",
    "    node_shapes = []\n",
    "    it_only_nodes = []\n",
    "    base_only_nodes = []\n",
    "    shared_nodes = []\n",
    "    unknown_nodes = []\n",
    "    df = feature_df()\n",
    "    for node in G.nodes():\n",
    "\n",
    "        tag = df.loc[int(node[1:]), \"tag\"]\n",
    "        if tag == \"IT only\":\n",
    "            node_colors.append(\"red\")\n",
    "            it_only_nodes.append(node)\n",
    "        elif tag == \"Base only\":\n",
    "            node_colors.append(\"blue\")\n",
    "            base_only_nodes.append(node)\n",
    "        elif tag == \"Shared\":\n",
    "            node_colors.append(\"green\")\n",
    "            shared_nodes.append(node)\n",
    "        else:\n",
    "            node_colors.append(\"gray\")\n",
    "            unknown_nodes.append(node)\n",
    "        if node[0] == \"i\":\n",
    "            if tag == \"Base only\":\n",
    "                raise Exception(f\"Base only node: {node}\")\n",
    "            node_shapes.append(\"*\")\n",
    "        else:\n",
    "            node_shapes.append(\"o\")\n",
    "        if df.loc[int(node[1:]), \"dead\"]:\n",
    "            raise Exception(f\"dead node: {node}\")\n",
    "    # Draw nodes with colors\n",
    "    draw_networkx_nodes(\n",
    "        G, pos, node_size=15, node_color=np.array(node_colors), node_shape=node_shapes\n",
    "    )\n",
    "\n",
    "    # Draw edges with width proportional to weight\n",
    "    edge_weights = [G[u][v][\"weight\"] for u, v in G.edges()]\n",
    "    nx.draw_networkx_edges(G, pos, width=[w * 1 for w in edge_weights], alpha=0.3)\n",
    "\n",
    "    # Add legend\n",
    "    plt.scatter([], [], c=\"red\", label=\"Chat only\", s=20)\n",
    "    plt.scatter([], [], c=\"blue\", label=\"Base only\", s=20)\n",
    "    plt.scatter([], [], c=\"green\", label=\"Shared\", s=20)\n",
    "    plt.scatter([], [], c=\"gray\", label=\"Other\", s=20)\n",
    "    plt.scatter([], [], c=\"black\", marker=\"*\", label=\"Chat latents\", s=20)\n",
    "    plt.scatter([], [], c=\"black\", marker=\"o\", label=\"Base latents\", s=20)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_interactive_graph(G, title=\"\"):\n",
    "    df = feature_df()\n",
    "    pos = nx.spring_layout(G, k=0.035)  # reduced k from default\n",
    "\n",
    "    # Create node color list and prepare for legend\n",
    "    it_only_nodes = []\n",
    "    base_only_nodes = []\n",
    "    shared_nodes = []\n",
    "    unknown_nodes = []\n",
    "\n",
    "    # Create lists for node traces\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_colors = []\n",
    "    node_symbols = []\n",
    "    node_texts = []  # Added for hover text\n",
    "    for node in G.nodes():\n",
    "        x, y = pos[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        node_texts.append(node)  # Add node name for hover\n",
    "\n",
    "        type = df.loc[int(node[1:]), \"tag\"]\n",
    "        if type == \"IT only\":\n",
    "            node_colors.append(\"red\")\n",
    "            it_only_nodes.append(node)\n",
    "        elif type == \"Base only\":\n",
    "            node_colors.append(\"blue\")\n",
    "            base_only_nodes.append(node)\n",
    "        elif type == \"Shared\":\n",
    "            node_colors.append(\"green\")\n",
    "            shared_nodes.append(node)\n",
    "        else:\n",
    "            node_colors.append(\"gray\")\n",
    "            unknown_nodes.append(node)\n",
    "\n",
    "        if node[0] == \"i\":\n",
    "            node_symbols.append(\"star\")\n",
    "        else:\n",
    "            node_symbols.append(\"circle\")\n",
    "\n",
    "        if df.loc[int(node[1:]), \"dead\"]:\n",
    "            raise Exception(f\"dead node: {node}\")\n",
    "\n",
    "    # Create edge traces\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    edge_weights = []\n",
    "\n",
    "    for edge in G.edges():\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_x.extend([x0, x1, None])\n",
    "        edge_y.extend([y0, y1, None])\n",
    "        edge_weights.append(G[edge[0]][edge[1]][\"weight\"])\n",
    "\n",
    "    # Create edge trace\n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x,\n",
    "        y=edge_y,\n",
    "        line=dict(width=1, color=\"black\"),\n",
    "        hoverinfo=\"none\",\n",
    "        mode=\"lines\",\n",
    "        opacity=0.6,\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    # Create node trace\n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode=\"markers\",\n",
    "        text=node_texts,  # Add hover text\n",
    "        hoverinfo=\"text\",  # Show the text on hover\n",
    "        marker=dict(size=15, color=node_colors, symbol=node_symbols),\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure(data=[node_trace, edge_trace])\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        showlegend=True,\n",
    "        hovermode=\"closest\",\n",
    "        margin=dict(b=0, l=0, r=0, t=40),\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "    )\n",
    "\n",
    "    # Add legend using shapes\n",
    "    legend_items = [\n",
    "        (\"Chat only\", \"red\", \"circle\"),\n",
    "        (\"Base only\", \"blue\", \"circle\"),\n",
    "        (\"Shared\", \"green\", \"circle\"),\n",
    "        (\"Other\", \"gray\", \"circle\"),\n",
    "        (\"Chat latents\", \"black\", \"star\"),\n",
    "        (\"Base latents\", \"black\", \"circle\"),\n",
    "    ]\n",
    "\n",
    "    for i, (name, color, symbol) in enumerate(legend_items):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[None],\n",
    "                y=[None],\n",
    "                mode=\"markers\",\n",
    "                name=name,\n",
    "                marker=dict(size=10, color=color, symbol=symbol),\n",
    "                showlegend=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "df = feature_df()\n",
    "df.iloc[[49685, 37320]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nullcontext():\n",
    "\n",
    "    # Create dataframe with P(A|B) and P(B|A) values\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"P(chat|base)\": P_A_given_B.cpu().numpy().flatten(),\n",
    "            \"P(base|chat)\": P_B_given_A.cpu().numpy().flatten(),\n",
    "            \"Pair\": twins.tolist(),\n",
    "        }\n",
    "    )\n",
    "    # add histogram of P(chat|base) and P(base|chat) in  a new figure\n",
    "    # Create subplots with 2 columns\n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "    # Add histogram for P(chat|base)\n",
    "    fig.add_trace(go.Histogram(x=df[\"P(chat|base)\"], name=\"P(chat|base)\"), row=1, col=1)\n",
    "\n",
    "    # Add histogram for P(base|chat)\n",
    "    fig.add_trace(go.Histogram(x=df[\"P(base|chat)\"], name=\"P(base|chat)\"), row=1, col=2)\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"Histograms of Conditional Probabilities\",\n",
    "        showlegend=False,\n",
    "        height=400,\n",
    "        width=800,\n",
    "    )\n",
    "\n",
    "    # Update x-axis labels\n",
    "    fig.update_xaxes(title_text=\"P(chat|base)\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"P(base|chat)\", row=1, col=2)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    # Create scatter plot\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=\"P(chat|base)\",\n",
    "        y=\"P(base|chat)\",\n",
    "        hover_data=[\"Pair\"],\n",
    "        title=\"P(chat|base) vs P(base|chat) for Each Latent Pair\",\n",
    "    )\n",
    "    # add a line at y = x\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[\n",
    "                min(df[\"P(chat|base)\"].min(), df[\"P(base|chat)\"].min()),\n",
    "                max(df[\"P(chat|base)\"].max(), df[\"P(base|chat)\"].max()),\n",
    "            ],\n",
    "            y=[\n",
    "                min(df[\"P(chat|base)\"].min(), df[\"P(base|chat)\"].min()),\n",
    "                max(df[\"P(chat|base)\"].max(), df[\"P(base|chat)\"].max()),\n",
    "            ],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"red\", dash=\"dash\"),\n",
    "            name=\"y=x\",\n",
    "        )\n",
    "    )\n",
    "    # add linear regression line\n",
    "    # Calculate linear regression\n",
    "    slope, intercept = np.polyfit(df[\"P(chat|base)\"], df[\"P(base|chat)\"], 1)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[\"P(chat|base)\"],\n",
    "            y=slope * df[\"P(chat|base)\"] + intercept,\n",
    "            mode=\"lines\",\n",
    "            name=f\"Linear fit (slope={slope:.2f})\",\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        xaxis_range=[\n",
    "            min(df[\"P(chat|base)\"].min(), df[\"P(base|chat)\"].min()) - 0.01,\n",
    "            max(df[\"P(chat|base)\"].max(), df[\"P(base|chat)\"].max()) + 0.01,\n",
    "        ],\n",
    "        yaxis_range=[\n",
    "            min(df[\"P(chat|base)\"].min(), df[\"P(base|chat)\"].min()) - 0.01,\n",
    "            max(df[\"P(chat|base)\"].max(), df[\"P(base|chat)\"].max()) + 0.01,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_baseline = th.load(\n",
    "    DATA_ROOT / \"/results/twins_baseline_activation_statistics_N10000000.pt\"\n",
    ")\n",
    "twins_baseline = th.tensor(json.load(open(\"../data/twins_baseline.json\")))\n",
    "P_A_given_B_baseline = results_baseline[\"count_joint\"] / results_baseline[\"count_B\"]\n",
    "P_B_given_A_baseline = results_baseline[\"count_joint\"] / results_baseline[\"count_A\"]\n",
    "with nullcontext():\n",
    "    # Create dataframe with P(A|B) and P(B|A) values\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"P(chat|base)\": P_A_given_B_baseline.cpu().numpy().flatten(),\n",
    "            \"P(base|chat)\": P_B_given_A_baseline.cpu().numpy().flatten(),\n",
    "            \"Pair\": twins_baseline.tolist(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # add histogram of P(chat|base) and P(base|chat) in  a new figure\n",
    "    # Create subplots with 2 columns\n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "    # Add histogram for P(chat|base)\n",
    "    fig.add_trace(go.Histogram(x=df[\"P(chat|base)\"], name=\"P(chat|base)\"), row=1, col=1)\n",
    "\n",
    "    # Add histogram for P(base|chat)\n",
    "    fig.add_trace(go.Histogram(x=df[\"P(base|chat)\"], name=\"P(base|chat)\"), row=1, col=2)\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"Histograms of Conditional Probabilities\",\n",
    "        showlegend=False,\n",
    "        height=400,\n",
    "        width=800,\n",
    "    )\n",
    "\n",
    "    # Update x-axis labels\n",
    "    fig.update_xaxes(title_text=\"P(chat|base)\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"P(base|chat)\", row=1, col=2)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    # Create scatter plot\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=\"P(chat|base)\",\n",
    "        y=\"P(base|chat)\",\n",
    "        hover_data=[\"Pair\"],\n",
    "        title=\"P(chat|base) vs P(base|chat) for Each Latent Pair\",\n",
    "    )\n",
    "    # add a line at y = x\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[\n",
    "                min(df[\"P(chat|base)\"].min(), df[\"P(base|chat)\"].min()),\n",
    "                max(df[\"P(chat|base)\"].max(), df[\"P(base|chat)\"].max()),\n",
    "            ],\n",
    "            y=[\n",
    "                min(df[\"P(chat|base)\"].min(), df[\"P(base|chat)\"].min()),\n",
    "                max(df[\"P(chat|base)\"].max(), df[\"P(base|chat)\"].max()),\n",
    "            ],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"red\", dash=\"dash\"),\n",
    "            name=\"y=x\",\n",
    "        )\n",
    "    )\n",
    "    # add linear regression line\n",
    "    # Calculate linear regression\n",
    "    slope, intercept = np.polyfit(df[\"P(chat|base)\"], df[\"P(base|chat)\"], 1)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[\"P(chat|base)\"],\n",
    "            y=slope * df[\"P(chat|base)\"] + intercept,\n",
    "            mode=\"lines\",\n",
    "            name=f\"Linear fit (slope={slope:.2f})\",\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        xaxis_range=[\n",
    "            min(df[\"P(chat|base)\"].min(), df[\"P(base|chat)\"].min()) - 0.01,\n",
    "            max(df[\"P(chat|base)\"].max(), df[\"P(base|chat)\"].max()) + 0.01,\n",
    "        ],\n",
    "        yaxis_range=[\n",
    "            min(df[\"P(chat|base)\"].min(), df[\"P(base|chat)\"].min()) - 0.01,\n",
    "            max(df[\"P(chat|base)\"].max(), df[\"P(base|chat)\"].max()) + 0.01,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
